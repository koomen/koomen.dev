<PageWrapper title="Horseless Carriages | koomen.dev">

# AI Horseless Carriages

I noticed something interesting the other day: I enjoy building with AI a lot more than I enjoy using most of the software that other people have built with AI. 

When I build with AI I feel like I can accomplish almost anything I can imagine very quickly. AI feels like a power tool. It's a lot of fun.

Most AI apps don't feel like that, though. They rarely do things the way that I want them done, and fixing that is often more work than just doing the thing myself. Using AI apps feels like a chore, like managing an underperforming employee.

This has been bugging me for a while and a few days ago I finally realized why. I am beginning to suspect that most of today's AI apps are horseless carriages.

In this essay I'm going to explain what I mean by that, and then do my best to make predictions about what apps that take full advantage of AI will look like. It is broken into three parts.

1. **Bad AI apps.** Here I'll describe the experience of using a bad AI app. I'm sure it will be familiar to most of you by now. 
2. **Riding in Horseless Carriages.** Here I'll explain why I think this particular flavor of bad AI app is the horseless carriage of our era. Then I'll ask and answer the question: what does a good AI app look like?
3. **Good AI apps.** Here I'll describe what I think good AI apps will look like. 

Alright, let's get started.

## Bad AI apps

A little while ago, the Gmail team released a new feature giving users to the ability to generate email drafts from scratch using Google's flagship AI model, Gemini. This is what it looks like:

<CaptionedImage 
  src="/images/gmail_prompt.png" 
  alt="Gmail's Gemini email draft feature with a prompt I've written" 
  caption="Gmail's Gemini email draft generation feature"
  size="large"
/>

Here I've added a prompt to the interface requesting a draft for an email to my boss. Let's see what Gemini returns:

<CaptionedImage 
  src="/images/gmail_response.png" 
  alt="Gmail's Gemini email draft generation feature response" 
  caption="Gmail's Gemini email draft generation feature response"
  size="large"
/>

As you can see, Gemini has produced a plausible sounding draft that fits the prompt I submitted perfectly. Tada. Mission accomplished right? No, of course not: this doesn’t sound anything like an email that I would actually write. If I'd written this email myself, it would have sounded something like this:

<CaptionedText
  size="large"
  caption="The email draft I would have written"
>
**Subject:** Pete OOO

**** woke up with the flu so I won't make it in today
</CaptionedText>

When you compare it with mine, Gemini's draft is wordy and weirdly formal and so un-Pete that if I actually sent this to Garry, he’d probably mistake it for some kind of phishing attack. It’s _AI Slop_.

Everyone who has used an LLM app to do any writing has had this experience. It’s so common that most of us have unconsciously adopted strategies for avoiding it when writing prompts. The simplest such strategy is just writing more detailed instructions that steer the LLM in the right direction, like this:

<CaptionedText
    size="large"
    caption="Prompt hacking our way to success"
>
let my boss garry know that **** woke up with the flu and that I won't be able to come in to the office today. Use no more than one line for the entire email body. Make it friendly but really concise. Don't worry about punctuation or capitalization. Sign off with “Pete” or “pete” and not “Best Regards, Pete” and certainly not “Love, Pete”
</CaptionedText>

But this is obviously dumb. Writing these instructions took longer than it would have taken me to write the email myself in the first place. Remarkably, the Gmail team has shipped a product that perfectly captures the experience of managing an underperforming employee. The AI in Gmail is braindead.

Why would the Gmail team ship something so obviously bad? To understand this we need to look under the hood:

## System Prompts and User Prompts

When viewed from the outside, large language models are actually really simple. They read in a stream of words, the “prompt”, and then start predicting the words, one after another, that are likely to come next, the “response”.






</PageWrapper>
